{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "MIE1624_final.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sli782/pho/blob/master/MIE1624_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yIEi7q4QSRF"
      },
      "source": [
        "# Imports\n",
        "from bs4 import BeautifulSoup\n",
        "import requests, json\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CoYugPLQSRI"
      },
      "source": [
        "# Scraping parameters\n",
        "fetching_list = {\n",
        "    'job_title':'Data Scientist',\n",
        "    'location':'Canada',\n",
        "    'pages':5 \n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3IsbRcJQSRL"
      },
      "source": [
        "def create_url(parameters):\n",
        "    # create base url for all further searches\n",
        "    title = parameters['job_title'].replace(\" \",\"+\")\n",
        "    place = parameters['location'].replace(\" \",\"+\")\n",
        "    base_url = f\"https://www.indeed.ca/jobs?q={title}&l={place}\"\n",
        "    return base_url"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQipwsl9QSRO"
      },
      "source": [
        "def get_desciption(j_title, j_soup, parameters):\n",
        "    # # rate job by keywords\n",
        "    \n",
        "    try:\n",
        "      description = j_soup.find(id=\"jobDescriptionText\").get_text()\n",
        "    except AttributeError:\n",
        "      description = \"Not Found\" \n",
        "    # keywords = parameters['ordered_keywords']\n",
        "    # title_keywords = parameters['title_keywords']\n",
        "    # exclude_keywords = parameters['exclude_keywords']\n",
        "    # total_keywords = len(keywords) + len(title_keywords)\n",
        "    # keywords_present = []\n",
        "    # title_keywords_present = []\n",
        "    # rating = 0\n",
        "    \n",
        "    # # Check for keyword, add value to rating depending on ranking\n",
        "    # for index,keyword in enumerate(keywords):\n",
        "    #     if keyword in description:\n",
        "    #         rating += len(keywords) - index\n",
        "    #         keywords_present.append(keyword)\n",
        "    \n",
        "    # # Check for title keywords\n",
        "    # for index,keyword in enumerate(title_keywords):\n",
        "    #     if keyword in j_title:\n",
        "    #         rating += total_keywords - index\n",
        "    #         title_keywords_present.append(keyword)\n",
        "    \n",
        "    # # Normalise rating\n",
        "    # rating = rating/sum(range(1,total_keywords+1))\n",
        "    \n",
        "    # # Check for excluded keywords\n",
        "    # for keyword in exclude_keywords:\n",
        "    #     if keyword in j_title:\n",
        "    #         rating = 0\n",
        "    #         break\n",
        "    \n",
        "    return description"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJFyKlIMQSRR"
      },
      "source": [
        "def get_job_details(job,parameters):\n",
        "    \n",
        "    # Get link and title\n",
        "    job_url = job.find(class_='title').a['href']\n",
        "    \n",
        "    # Correct for truncated URLs\n",
        "    job_url = \"https://www.indeed.ca\" + job_url if (job_url.startswith(\"/\")) else job_url\n",
        "    job_page = requests.get(job_url)\n",
        "    job_soup = BeautifulSoup(job_page.content,'html.parser')\n",
        "    \n",
        "    # Give URL after redirect (ads/analytics etc.)\n",
        "    job_url = job_page.url \n",
        "    print(job_url)\n",
        "    # Get job title and company name\n",
        "    try:\n",
        "      title = job.find(class_='title').a['title']\n",
        "    except AttributeError:\n",
        "      title = \"Not Found \"\n",
        "    \n",
        "    try:\n",
        "      company = job_soup.find(class_=\"icl-u-lg-mr--sm\").get_text()\n",
        "    except AttributeError:\n",
        "      company = \"Not Found \"\n",
        "    \n",
        "    \n",
        "    # Get description, rating and present keywords\n",
        "    description = get_desciption(title,job_soup,parameters)\n",
        "    print(title, \" \", company)\n",
        "    return title, company, job_url, description"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDLbDzXmQSRU"
      },
      "source": [
        "def scrape(parameters):\n",
        "    \n",
        "    # Create base url for all further searches\n",
        "    base_url = create_url(parameters)\n",
        "    \n",
        "    # Output list and frame\n",
        "    output = []\n",
        "    \n",
        "    for x in range(0,parameters['pages']):\n",
        "        if(x==0):\n",
        "            page_append = \"\"\n",
        "        else: \n",
        "            page_append = \"&start=\" + str(x*10)\n",
        "            \n",
        "        # get page\n",
        "        current_page = requests.get(base_url+page_append,timeout=5)\n",
        "        page_soup = BeautifulSoup(current_page.content,\"html.parser\")\n",
        "        \n",
        "        for job in page_soup.select(\".jobsearch-SerpJobCard\"):\n",
        "            title, company, url, description= get_job_details(job,parameters)\n",
        "            output.append([title,company,description,url,x+1])\n",
        "            \n",
        "        print(f\"Page {x+1} completed\",end=\"\\r\")\n",
        "        \n",
        "    df_output_frame = pd.DataFrame(\n",
        "        output,columns=['Job Title','Company','Description','Job URL''Page Found']).sort_values(\n",
        "        by='Job Title',ascending=False).reset_index(drop=True)\n",
        "\n",
        "    return df_output_frame\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "L68hurfNQSRX",
        "outputId": "bd04caa5-5249-4cda-d7da-296d498d08fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "jobs = scrape(fetching_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://ca.indeed.com/viewjob?jk=5321f7ac707aaede&from=serp&vjs=3\n",
            "Data Scientist   Technical Safety BC\n",
            "https://ca.indeed.com/viewjob?jk=2367108563271394&from=serp&vjs=3\n",
            "20-78 Data Scientist (Closing Date: November 22, 2020)   Technical Safety BC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n419dnfQSRa"
      },
      "source": [
        "display(jobs.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3NR4yZXQSRe"
      },
      "source": [
        "# Output to Excel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "M2GsiWDFQSRf"
      },
      "source": [
        "with pd.ExcelWriter('Excel Output.xlsx',options={'strings_to_urls': False}) as writer:\n",
        "    jobs.to_excel(writer,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuwTr4UGQSRj"
      },
      "source": [
        "# Example output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em0OPAnRQSRj"
      },
      "source": [
        "<img src=\"img/Example_Output.PNG\">"
      ]
    }
  ]
}